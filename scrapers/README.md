# Modular Scraper System

Sistema modular para integra√ß√£o com m√∫ltiplas casas de apostas (bookmakers) para coleta de odds de esports.

## Estrutura

```
scrapers/
‚îú‚îÄ‚îÄ base_scraper.py          # Classe base abstrata
‚îú‚îÄ‚îÄ config.py                # Configura√ß√µes e flags enabled/disabled
‚îú‚îÄ‚îÄ scraper_manager.py       # Gerenciador de todos os scrapers
‚îÇ
‚îú‚îÄ‚îÄ active/                  # Casas ativas
‚îÇ   ‚îú‚îÄ‚îÄ superbet.py          # ‚úÖ Scraper Superbet (ATIVO)
‚îÇ   ‚îî‚îÄ‚îÄ stake.py             # ‚úÖ API Stake.com (ATIVO)
‚îÇ
‚îú‚îÄ‚îÄ traditional/             # Casas tradicionais (desabilitadas)
‚îÇ   ‚îú‚îÄ‚îÄ bet365.py            # ‚è∏Ô∏è DESABILITADO
‚îÇ   ‚îú‚îÄ‚îÄ betano.py            # ‚è∏Ô∏è DESABILITADO
‚îÇ   ‚îú‚îÄ‚îÄ sportingbet.py       # ‚è∏Ô∏è DESABILITADO
‚îÇ   ‚îú‚îÄ‚îÄ betfair.py           # ‚è∏Ô∏è DESABILITADO
‚îÇ   ‚îú‚îÄ‚îÄ onexbet.py           # ‚è∏Ô∏è DESABILITADO (1xBet)
‚îÇ   ‚îú‚îÄ‚îÄ pinnacle.py          # ‚è∏Ô∏è DESABILITADO
‚îÇ   ‚îî‚îÄ‚îÄ kto.py               # ‚è∏Ô∏è DESABILITADO
‚îÇ
‚îî‚îÄ‚îÄ crypto/                  # Casas cripto (desabilitadas)
    ‚îú‚îÄ‚îÄ bcgame.py            # ‚è∏Ô∏è DESABILITADO
    ‚îú‚îÄ‚îÄ cloudbet.py          # ‚è∏Ô∏è DESABILITADO
    ‚îú‚îÄ‚îÄ spartans.py          # ‚è∏Ô∏è DESABILITADO
    ‚îî‚îÄ‚îÄ thunderpick.py       # ‚è∏Ô∏è DESABILITADO
```

## Status das Casas

### üü¢ Casas ATIVAS (funcionando)
1. **Superbet** - Scraper
2. **Stake.com** - API P√∫blica (docs: https://docs.stake.com/)

### üü° Casas DESABILITADAS (aguardando configura√ß√£o)
- Bet365
- Betano
- Sportingbet
- Betfair
- 1xBet
- Pinnacle
- KTO

### üîµ Casas Cripto DESABILITADAS (verificar API/scraper depois)
- BC.Game
- Cloudbet
- Spartans
- Thunderpick

## Uso

### Exemplo B√°sico

```python
import asyncio
from scrapers.scraper_manager import scraper_manager
from scrapers.active.superbet import SuperbetScraper
from scrapers.active.stake import StakeScraper

async def main():
    # Registrar scrapers
    scraper_manager.register_scraper(SuperbetScraper())
    scraper_manager.register_scraper(StakeScraper())
    
    # Listar scrapers habilitados
    enabled = scraper_manager.get_enabled_scrapers()
    print(f"Scrapers ativos: {[s.name for s in enabled]}")
    
    # Buscar odds de todas as casas
    all_odds = await scraper_manager.fetch_all_odds(game="cs2")
    
    # Comparar odds entre casas
    comparisons = await scraper_manager.compare_odds(game="lol")

if __name__ == "__main__":
    asyncio.run(main())
```

### Executar Exemplo Completo

```bash
python example_scraper_usage.py
```

## Classe Base: BaseScraper

Todos os scrapers herdam de `BaseScraper` e implementam:

- `async def get_esports_odds(game: str = None) -> List[OddsData]`
- `async def get_live_events() -> List[Dict]`
- `async def health_check() -> bool`

## Formato de Dados: OddsData

```python
@dataclass
class OddsData:
    event_id: str
    event_name: str
    sport: str
    league: str
    team_home: str
    team_away: str
    odds_home: float
    odds_draw: Optional[float]
    odds_away: float
    bookmaker: str
    timestamp: str
    extra_markets: Optional[Dict] = None
```

## Configura√ß√£o

As configura√ß√µes est√£o em `scrapers/config.py`:

```python
BOOKMAKERS_CONFIG = {
    "superbet": {
        "enabled": True,
        "type": "scraper",
        "category": "traditional",
        "base_url": "https://superbet.com",
        "priority": 1
    },
    # ...
}
```

## Como Habilitar uma Casa Desabilitada

1. Abrir o arquivo do scraper (ex: `scrapers/traditional/bet365.py`)
2. Implementar os m√©todos `get_esports_odds`, `get_live_events`, `health_check`
3. Atualizar `enabled=True` em `scrapers/config.py`
4. Testar a implementa√ß√£o

## Gerenciador de Scrapers

O `ScraperManager` fornece:

- `register_scraper(scraper)` - Registra um scraper
- `get_enabled_scrapers()` - Lista scrapers habilitados
- `fetch_all_odds(game)` - Busca odds de todos os scrapers
- `compare_odds(game)` - Compara odds entre casas
- `health_check_all()` - Verifica sa√∫de de todos os scrapers

## Depend√™ncias

As depend√™ncias necess√°rias j√° est√£o em `requirements.txt`:

- `aiohttp` - Cliente HTTP ass√≠ncrono
- `beautifulsoup4` - Parser HTML para scrapers
- `selenium` - Automa√ß√£o de navegador (quando necess√°rio)
- `requests` - Cliente HTTP simples
